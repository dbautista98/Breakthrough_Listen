{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was originally written by Karen Perez, for GBT C-Band data. I generalized this code to calculate the spike channels for other bands at GBT. It now takes in an h5/filterbank file and its corresponding .dat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blimpy.io.base_reader WARNING  Selection size of 19.25 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "\n",
      "--- File Info ---\n",
      "DIMENSION_LABELS : [b'frequency' b'feed_id' b'time']\n",
      "        az_start :                              0.0\n",
      "       data_type :                                1\n",
      "            fch1 :                1926.26953125 MHz\n",
      "            foff :      -2.7939677238464355e-06 MHz\n",
      "      machine_id :                               20\n",
      "           nbits :                               32\n",
      "          nchans :                        322961408\n",
      "            nifs :                                1\n",
      "     source_name :                         HIP82860\n",
      "         src_dej :                     65:08:06.008\n",
      "         src_raj :                      16:56:01.98\n",
      "    telescope_id :                                6\n",
      "           tsamp :                     18.253611008\n",
      "   tstart (ISOT) :          2016-10-03T22:09:21.000\n",
      "    tstart (MJD) :               57664.923159722224\n",
      "        za_start :                              0.0\n",
      "\n",
      "Num ints in file :                               16\n",
      "      File shape :               (16, 1, 322961408)\n",
      "--- Selection Info ---\n",
      "Data selection shape :               (16, 1, 322961408)\n",
      "Minimum freq (MHz) :               1023.9257840439677\n",
      "Maximum freq (MHz) :                    1926.26953125\n"
     ]
    }
   ],
   "source": [
    "f = bl.Waterfall(h5_files[9])\n",
    "f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1023.9257784560323"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1926.26953125 + 322961409*-2.7939677238464355e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import blimpy as bl\n",
    "import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_files = [\n",
    "    \"dat_files/GBT_57523_69379_HIP17147_fine.dat\", \n",
    "    \"dat_files/GBT_57606_50058_HIP20901_fine.dat\",\n",
    "    \"dat_files/GBT_57456_02669_HIP39826_fine.dat\",\n",
    "    \"dat_files/GBT_57803_80733_HIP4436_fine.dat\",  \n",
    "    \"dat_files/GBT_57599_55512_HIP45493_fine.dat\", \n",
    "    \"dat_files/GBT_57459_34297_HIP65352_fine.dat\", \n",
    "    \"dat_files/GBT_57650_54573_HIP66704_fine.dat\", \n",
    "    \"dat_files/GBT_57523_22406_HIP74981_fine.dat\", \n",
    "    \"dat_files/GBT_57680_15520_HIP7981_fine.dat\",  \n",
    "    \"dat_files/GBT_57664_79761_HIP82860_fine.dat\" \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_files = [\n",
    "    \"/mnt_blpd7/datax/dl/GBT_57523_69379_HIP17147_fine.h5\",\n",
    "    \"/mnt_blpd7/datax/dl/GBT_57606_50058_HIP20901_fine.h5\",\n",
    "    \"/mnt_blpd7/datax/dl/GBT_57456_02669_HIP39826_fine.h5\",\n",
    "    \"/mnt_blpd7/datax2/dl/GBT_57803_80733_HIP4436_fine.h5\",\n",
    "    \"/mnt_blpd7/datax/dl/GBT_57599_55512_HIP45493_fine.h5\",\n",
    "    \"/mnt_blpd7/datax/dl/GBT_57459_34297_HIP65352_fine.h5\",\n",
    "    \"/mnt_blpd7/datax2/dl/GBT_57650_54573_HIP66704_fine.h5\",\n",
    "    \"/mnt_blpd7/datax/dl/GBT_57523_22406_HIP74981_fine.h5\",\n",
    "    \"/mnt_blpd7/datax2/dl/GBT_57680_15520_HIP7981_fine.h5\",\n",
    "    \"/mnt_blpd7/datax2/dl/GBT_57664_79761_HIP82860_fine.h5\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_parameters(h5_file):\n",
    "    \"\"\"takes h5 file of GBT data and returns a list of channels and nfpc\n",
    "\n",
    "    returns channels_list, fch1, foff, nfpc\"\"\"\n",
    "    #read h5 file and grab frequency info from the header\"\n",
    "    test_file = h5_file\n",
    "    fb = bl.Waterfall(test_file, load_data=False)\n",
    "    head = fb.file_header\n",
    "    \n",
    "    fch1 = head[\"fch1\"]\n",
    "    foff = head[\"foff\"]\n",
    "    nchans=head[\"nchans\"]\n",
    "    fch1=float(fch1-(foff/2.0))\n",
    "    \n",
    "    nfpc=(1500.0/512.0)/abs(foff)\n",
    "    channels_list=range(0,nchans+1)\n",
    "    \n",
    "    return channels_list, fch1, foff, nfpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `spike_channels` function is not a very efficient cell. It would be worth looking into to see if there are more efficient ways to make the list. \n",
    "\n",
    "It seems like we are just making a list that increments at some intervals (hopefully a periodic interval), so it would be worth seeing if we can use a numpy function to make it faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524288.0, 338649581879296.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_channels_list[0], spike_channels_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_channels(channels_list, nfpc):\n",
    "    \"\"\"makes a spike channels list given a list of channels\"\"\"\n",
    "    spike_channels_list=[]\n",
    "    for i in channels_list: #should be smaller ~512 -> variable somewhere to store this that can be changed course channels list? \n",
    "        spike_channel=(nfpc/2.0)+(nfpc*i)\n",
    "        spike_channels_list.append(spike_channel)\n",
    "    print ('spike channels list done')\n",
    "    return spike_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqs_fine_channels(spike_channels_list, fch1, foff):\n",
    "    \"\"\"docstring here\"\"\"\n",
    "    freqs_fine_channels_list=[]\n",
    "    for index, value in enumerate(spike_channels_list):\n",
    "        freq_fine_channel=fch1+foff*value\n",
    "        if freq_fine_channel>0:\n",
    "            #print ('freq_fine_channel', freq_fine_channel)\n",
    "            #num = str(freq_fine_channel)\n",
    "            #i = num.index(\".\")\n",
    "            #freq_fine_channel = num[:i + 7]\n",
    "            freq_fine_channel=round(freq_fine_channel, 6)\n",
    "            freqs_fine_channels_list.append(freq_fine_channel)\n",
    "        else:\n",
    "            break\n",
    "    #print ('freqs_fine_channels list done', freqs_fine_channels_list)\n",
    "    print ('end')\n",
    "    np.save('freqs_fine_channels_list2.npy', freqs_fine_channels_list)\n",
    "    return freqs_fine_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_function(dat_file, freqs_fine_channels_list):\n",
    "    \"\"\"a wrapper function to encapsulate a function that I want to call multiple times\"\"\"\n",
    "    file = dat_file\n",
    "\n",
    "    if True:#\"gpuspec.0000.dat\" in file and (\"A00_0025\" in file or \"C01_0026\" in file or \"C07_0027\" in file or \"A00_0028\" in file or \"C01_0029\" in file or \"C07_0030\" in file or \"A00_0031\" in file or \"C01_0032\" in file):\n",
    "    #if file.endswith(\"gpuspec.0000.dat\") and \"A00_0025\" in file:    \n",
    "        datfile_curr=file\n",
    "        print ('datfile_curr', datfile_curr)\n",
    "        #data=np.loadtxt(datfile_curr)\n",
    "        file_contents = []\n",
    "        # open file you wish to read\n",
    "        with open(datfile_curr, 'r') as infile:\n",
    "            for line in infile:\n",
    "                file_contents.append(line)\n",
    "        with open(datfile_curr+'new.dat', 'w') as outfile:\n",
    "            for index, row in enumerate(file_contents):\n",
    "                #row=row.split('\\t')\n",
    "                #print ('row', row)\n",
    "                if index==0 or index==1 or index==2 or index==3 or index==4 or index==5 or index==6 or index==7 or index==8:\n",
    "                    #newrow=row.strip('\\n')\n",
    "                    newrow=row.strip('\\t')\n",
    "                    #print ('row', newrow)\n",
    "                    outfile.write(newrow)       \n",
    "                else:\n",
    "                    newrow=row.split('\\t')\n",
    "                    #print ('row', row)\n",
    "                    row=row.split('\\t')\n",
    "                    #print ('row_postsplit', row)\n",
    "                    freq=float(newrow[4])-(foff/2.0)\n",
    "                    startfreq=float(newrow[6])-(foff/2.0)\n",
    "                    endfreq=float(newrow[7])-(foff/2.0)\n",
    "                    #freq=freq.strip(' ')\n",
    "                    freq=round(freq, 6)\n",
    "                    startfreq=round(startfreq,6)\n",
    "                    endfreq=round(endfreq,6)\n",
    "                    #print ('freq', freq)\n",
    "                    #row[3]=str(freq)\n",
    "                    #row[4]=str(freq)\n",
    "                    #print ('rowwithadjfreq', row)\n",
    "                    #string='\\t'\n",
    "                    #row = [i + string for i in row]\n",
    "\n",
    "                    minfreq=(float(freq)-0.000001)\n",
    "                    maxfreq=(float(freq)+0.000001)\n",
    "                    #print ('minfreq', minfreq)\n",
    "                    #print ('maxfreq', maxfreq)\n",
    "                    #i= minfreq.index(\".\")\n",
    "                    #minfreq = minfreq[:i + 7]\n",
    "                    minfreq=round(minfreq,6)\n",
    "                    #j= maxfreq.index(\".\")\n",
    "                    #maxfreq = maxfreq[:j + 7]\n",
    "                    maxfreq=round(maxfreq,6)\n",
    "                    #print ('minfreq', minfreq)\n",
    "                    #print ('maxfreq', maxfreq)\n",
    "                    freq=str(freq)\n",
    "                    minfreq=str(minfreq)\n",
    "                    maxfreq=str(maxfreq)\n",
    "                    if len((freq).split('.')[1])<6:\n",
    "                        freq=format(float(freq), '.6f')\n",
    "                    row[3]=str(freq)\n",
    "                    row[4]=str(freq)\n",
    "                    row[6]=str(startfreq)\n",
    "                    row[7]=str(endfreq)\n",
    "                    string='\\t'\n",
    "                    for index,value in enumerate(row[:-1]):\n",
    "                        newvalue=value+string\n",
    "                        row[index]=newvalue\n",
    "                    #row = [i + string for i in row[:-1]]\n",
    "                    if len((minfreq).split('.')[1])<6:\n",
    "                        minfreq=format(float(minfreq), '.6f')\n",
    "                    if len((maxfreq).split('.')[1])<6:\n",
    "                        maxfreq=format(float(maxfreq), '.6f')\n",
    "                    #print ('freq', freq)\n",
    "                    #print ('minfreq', minfreq)\n",
    "                    #print ('maxfreq', maxfreq)\n",
    "                    if float(freq) in freqs_fine_channels_list:\n",
    "                        pass#print ('bad freq', freq)\n",
    "                    elif float(minfreq) in freqs_fine_channels_list:\n",
    "                        pass#print ('bad min freq', minfreq)\n",
    "                    elif float(maxfreq) in freqs_fine_channels_list:\n",
    "                        pass#print ('bad max freq', maxfreq)\n",
    "                    else:\n",
    "                        glue='  '\n",
    "                        #row=row.format()\n",
    "                        row=glue.join(row)\n",
    "                        #row=row.format()\n",
    "                        #print ('finalrow', row)\n",
    "                        outfile.write(str(row))\n",
    "    print(\"done!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blimpy.io.base_reader INFO     Skipping loading data ...\n"
     ]
    }
   ],
   "source": [
    "chan_list, fch1, foff, nfpc = grab_parameters(h5_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spike channels list: 100%|██████████| 318230529/318230529 [04:30<00:00, 1175579.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike channels list done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "spike_channels_list = spike_channels(chan_list, nfpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322961409"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chan_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "freqs_fine_channels_list = freqs_fine_channels(spike_channels_list,fch1, foff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datfile_curr dat_files/GBT_57523_69379_HIP17147_fine.dat\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "wrapper_function(dat_files[0], freqs_fine_channels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to generalize this one step further\n",
    "\n",
    "I will make a for loop that passes throught the whole `dat_files` and `h5_files` lists and performs these functions on each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blimpy.io.base_reader WARNING  Selection size of 18.97 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57523_69379_HIP17147_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 19.25 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57606_50058_HIP20901_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 15.77 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57456_02669_HIP39826_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 19.25 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57803_80733_HIP4436_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 19.25 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57599_55512_HIP45493_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 15.77 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57459_34297_HIP65352_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 19.25 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57650_54573_HIP66704_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 18.97 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57523_22406_HIP74981_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 19.25 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57680_15520_HIP7981_fine.dat\n",
      "done!\n",
      "blimpy.io.base_reader WARNING  Selection size of 19.25 GB, exceeding our size limit 1.00 GB. Instance created, header loaded, but data not loaded, please try another (t,v) selection.\n",
      "spike channels list done\n",
      "end\n",
      "datfile_curr dat_files/GBT_57664_79761_HIP82860_fine.dat\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dat_files)):\n",
    "    chan_list, fch1, foff, nfpc = grab_parameters(h5_files[i])\n",
    "    spike_channels_list = spike_channels(chan_list, nfpc)\n",
    "    freqs_fine_channels_list = freqs_fine_channels(spike_channels_list,fch1, foff)\n",
    "    wrapper_function(dat_files[i], freqs_fine_channels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
